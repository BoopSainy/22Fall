之前我所了解的大多是 discriminative model，对于一个分类任务，这种模型它主要的任务就是在学习一个函数f(x,y) = p(y|x)，也就是
给定一个输入，我们想要知道它在不同类别下的概率值是多少；

generative model则会对x和y的联合分布p(x,y)建模


variational autoencoder:

in just three years, variational autoencoers have emerged as one of the most popular approaches
to unsupervised learning of complicated distributions.  vaes are appealing because they are built
on top of standard function approximators (neural networks), and can be trained with stochastic
gradient descent. vaes have already shown promise in generating many kinds of complicated data,
including handwritten digits, faces, house numbers, cifar images, physical models of scenes, 
segmentation, and predicting the future from static images. this tutorial introduces the intuitions
behind vaes, explains the mathematics behind them, and describes some empirical behavior.

introduction;

generative modeling is a broad area of machine learning which deals with models of distribution

one most straightforward and simplest generative model: model the images in our training dataset;
we could estimate a p(x), when we have a new image, if this image is similar to the training images,
p(x) would be high, otherwise, p(x) would be low if this image is a random noise.
but this kind of generative model is not useful, because it is not useful if we want to synthesize
a new image like the training images.


instead, one often cares about producing more examples that are like those already in a database,
我们在乎的是生成更多的样本，这些样本很像数据集中的样本，但又不完全一样, but not exactly the same.
we could start with a database of raw images






